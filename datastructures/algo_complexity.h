#ifndef ALGO_COMPLEXITY_H
#define ALGO_COMPLEXITY_H

/*
Сложность любого кода можно оценить с точки зрения потребляемой памяти и времени выполнения.
Обычно сложность кода оценивают с точки зрения сложности _алгоритма_, который воплощен в коде.
Алгоритм - это последовательность инструкций, приводящих к решению задачи. При составлении
решения задачи обычно требуется оценить, насколько наш алгоритм хорош. Для этого обычно
используют следующий математический аппарат:

Возьмем две функции, T(N) и f(N).

1. T(N) = O(f(N)), если существуют положительные константы c и n₀, такие что T(N) <= cf(N)
   при N>=n₀

2. T(N) = Ω(f(N)), если существуют положительные константы c и n₀, такие что T(N) >= cf(N)
   при N>=n₀

3. T(N) = Θ(f(N)) тогда и только тогда, когда T(N) = O(f(N)) и T(N) = Ω(f(N))

4. T(N) = o(f(N)), если для любого положительного c существует положительная константа n₀, такая что T(N) < cf(N)
   при N>n₀. Менее формальное определение: T(N) = o(f(N)), если T(N) = O(f(N)) и T(N) != Θ(f(N))

Эти определения дают нам возможность задать относительную упорядоченность среди функций.
Для двух произвольных функций обычно есть точки, в которых одна функция меньше другой,
и точки, в которых это неверно. Таким образом, утверждение f(N) < g(N) часто не имеет смысла.
Вместо этого можно сравнивать ОТНОСИТЕЛЬНУЮ СКОРОСТЬ РОСТА функций.
Пример: функция y1 = 1000N больше функции y2 = N² для малых N, но N² растет быстрее, чем 1000N,
то есть y2 "больше" y1. Точка пересечения графиков - число N = 1000. Первое определение говорит нам,
что существует такая точка n₀, при превышении которой значение cf(N) как минимум не меньше T(N).
В нашем случае T(N) = 1000N, f(N) = N², n₀ = 1000, c = 1. Мы можем также использовать n₀ = 10 и c = 100.
То есть мы можем сказать, что 1000N = O(N²).

Если мы используем обычную терминологию "больше-меньше", то первое определение говорит нам,
что скорость роста T(N) не больше скорости роста f(N).
Второе определение - T(N) = Ω(f(N)) - говорит нам, что скорость роста T(N) не меньше скорости роста f(N).
Третье определение - T(N) = Θ(f(N)) - говорит нам, что скорость роста T(N) равна скорости роста f(N).
Четвертое определение - T(N) = o(f(N)) - говорит нам, что скорость роста T(N) меньше скорости роста f(N).
Когда мы говорим, что T(N) = O(f(N)), это значит, что f(N) является ВЕРХНЕЙ ГРАНИЦЕЙ для оценки
скорости роста T(N). Это значит также, что T(N) является НИЖНЕЙ ГРАНИЦЕЙ для f(N), т.е. T(N) = Ω(f(N)).

Пример: N³ растет быстрее, чем N², то есть N² = O(N³), и N³ = Ω(N²).
N² и 2N² растут с одной скоростью, так что справедливы утверждения N² = O(2N²) и N² = Ω(2N²).


При оценке функций на практике эти определения редко используются напрямую. Обычно применяют
набор методик и ранее установленных утверждений о функциях.
Правило 1: Если T1(N) = O(f(N)) и T2(N) = O(g(N)), то
    а) T1(Т) + T2(N) = O(f(N) + g(N))
    б) T1(N) * T2(N) = O(f(N) * g(N))
Правило 2: Если T(N) - полином степени k, то T(N) = Θ(N^k).
Правило 3: (log N)^k = O(N), то есть логарифмы растут очень медленно.

Таблица: скорости роста основных функций (по возрастанию)
----------------------------------------
c         константная
log N     логарифмическая
log²N     квадратно-логарифмическая
N         линейная
N log N   линейно-логарифмическая
N²        квадратичная
N³        кубическая
2^N       экспоненциальная

Дополнение 1: Константы и члены меньшего порядка исключаются при расчете O(f).
Не используйте запись T(N) = O(2N²) или T(N) = O(N²+N). Корректная запись здесь: T(N) = O(N²).
Это значит, что при анализе мы можем игнорировать все части функции, которые меньше старшего члена,
и избавляться от любых константных множителей.
Дополнение 2: Мы всегда можем оценить относительную скорость роста функций f и g, вычислив
предел lim (f(N)/g(N)) при N->∞
  - если lim=0, то f(N) = o(g(N)
  - если lim=c≠0, то f(N) = Θ(g(N))
  - если lim=∞, то f(N) = o(g(N))
  - если предел не существует, то оценить скорость невозможно.

Использование дополнения 2 позволяет сравнить сложность любых двух функций, но обычно
требует сложных расчетов. На практике пользуются правилами и таблицей скорости роста.

Пример: оценим N log N и N^1.5. Пользуясь правилом 1б, разделим обе функции на N:
log N <-> N^0.5. Пользуясь тем же правилом, возведем обе функции в квадрат:
log²N <-> N. Из таблицы видим, что log²N = O(N).

Практический пример: оценим сложность скачивания файла из интернета. Пусть на установление
соединения требуется 3 секунды, после чего скорость скачивания составляет 1,5 МБ/с.
Таким образом, скачивание файла в N МБ займет T(N) = N/1,5+3 секунд. Это линейная функция,
то есть T(N) = O(N).
Скачивание файла в 1500МБ (1003 сек) займет примерно вдвое больше времени, чем скачивание
файла в 750 МБ (503 сек). Если мы увеличим скорость скачивания вдвое, то время скачивания
обоих файлов уменьшится, но скачивание большего файла все так же займет в два раза больше времени.
Это типичное поведение линейной функции, объясняющее, почему мы можем игнорировать
константные множители.

При анализе реальных алгоритмов, а не математических функций, в первую очередь оценивают
общее время работы алгоритма. При этом в расчет не берут ни производительность компьютера
(так как она будет учитываться в худшем случае как константный множитель), ни особенности
реализации алгоритма на конкретном языке (так как их влияние оценить достаточно сложно).
Во вторую очередь учитывают объем входных данных (значение N). При этом время, необходимое
на чтение данных, также обычно не учитывают. Однако следует иметь в виду, что при малой
сложности алгоритма с возрастанием N общее время, требуемое на выполнение алгоритма,
может больше зависеть от величины N (от времени, затрачиваемого на чтение данных), чем от
сложности самого алгоритма.

При анализе алгоритма обычно определяют две функции - Tavg(N) и Tworst(N) - среднее время
выполнения и худшее время выполнения. Соответственно, Tavg(N) <= Tworst(N). Программистов
в первую очередь интересует сложность Tworst(N), который позволяет оценить гарантированное
время выполнения, дольше которого алгоритм работать не будет при любых, даже самых плохих,
входных данных. Tavg(N) представляет типичные случаи при обычных входных данных.  Изредка
оценивают Tbest(N) - лучшее время выполнения, хотя практически такая оценка бесполезна.

Например, при линейном поиске в массиве мы перебираем элементы массива один за другим.
Если мы найдем элемент сразу, то получим константное время выполнения: Tbest = 1.
Если мы найдем элемент где-то в середине массива, то среднее время выполнения будет колебаться
2 <= Tavg <= N-1. Если же искомый элемент - последний или вовсе отсутствует, то мы переберем
все элементы, то есть Tworst = N. Таким образом, как и предполагает название, линейный
поиск имеет сложность O(N).

Практический пример оценки времени выполнения кода
--------------------------------------------------

Пусть требуется оценить код расчета суммы кубов чисел от 1 до N
int sum(int N)
{
1    int partialSum;
2    partialSum = 0;
3    for (int i = 1; i <= n; ++i)
4        partialSum += i*i*i;
5    return partialSum;
}
Объявление переменной не требует времени.
Строки 2 и 5 требуют одной единицы времени.
Строка 4 требует 4 единиц времени - 3 на умножение и 1 на присвоение, и выполняется N раз,
то есть длительность тела цикла равна 4N.
Строка 3 включает скрытое присвоение (1, так как выполняется один раз),
проверку i<=N (выполняется N+1 раз) и увеличение i (выполняется N раз). То есть длительность
строки 2 равна 2N+2. Таким образом, игнорируя время вызова функции sum, получаем длительность
функции 6N+4, то есть, отбрасывая множитель и константу, получаем sum(N) = O(N), то есть линейную
сложность.

Один раз оценив сложность некоторых операций, в дальнейшем можно пользоваться результатами
эмпирически. То есть, строка 4 очевидно имеет константную сложность, поэтому нам неважна
точная длительность ее выполнения - 2, 3 или 4 единицы. Строки 1 и 2 очевидно выполняются
быстрее, чем тело цикла, поэтому мы можем исключить их из анализа. Таким образом, сформулируем
ряд эмпирических правил оценки кода:

Правило 1 - циклы
-----------------
Максимальное время выполнения цикла не превышает времени выполнения тела цикла, умноженного
на количество итераций цикла.

Правило 2 - вложенные циклы
---------------------------
Анализ времени начинается с внутреннего цикла. Общее время выполнения равно времени выполнения
тела цикла, умноженного на количество итераций каждого цикла.
Пример: сложность следующего алгоритма равна O(N²):
for (int i=0; i<N; ++i)
  for (int j=0; j<N; ++j)
    ++k;

Правило 3 - последовательные инструкции
---------------------------------------
Время выполнения двух последовательных инструкций равно сумме времен выполнения каждой
инструкции, а сложность всего алгоритма равна максимальной сложности этих инструкций.
Пример: сложность следующего фрагмента равна O(N²), так как сложность первого цикла равна O(N),
а сложность второго - O(N²), общее время выполнения равно N+N² (без учета констант и множителей).
for (int i=0; i<n; ++i) a[i]=0;
for (int i=0; i<n; ++i) {
  for (int j=0; j<n; ++j)
    a[i] += a[j]+i+j;
}

Правило 4 - условия
-------------------
Время выполнения условия if/else не превышает времени проверки условия плюс максимального
времени выполнения веток условия.
Пример: в зависимости от значения y время выполнения может быть либо квадратичным, либо
линейным, но максимальная сложность в любом случае не превышает квадратичной.
if (y==0)
    for (int i=0; i<n; ++i) a[i]=0;
else {
    for (int i=0; i<n; ++i) {
        for (int j=0; j<n; ++j)
            a[i] += a[j]+i+j;
    }
}

Можно сформулировать другие правила, но обычно ограничиваются этими четырьмя.
Если в коде есть вызовы функций, то сначала оценивают сложность тела функций.
Если в коде есть рекурсия, то оценка сложности кода может потребовать дополнительных усилий.
Обычно самое очевидное решение будет и самым неоптимальным.

--------------------------------------------------------------------------------
Проведем анализ сложности алгоритмов поиска максимальной суммы подпоследовательности.
Пусть у нас есть вектор целых чисел длиной N, содержащий как положительные, так и отрицательные
числа. Требуется найти такую подоследовательность в нем, что сумма ее элементов будет максимально
возможной. Например, для вектора (-2, 11, -4, 13, -5, -2) максимальной подпоследовательностью будет
(11, -4, 13) - сумма равна 20.
Существует множество алгоритмов решения этой задачи. Разберем 4 алгоритма, начиная с самого очевидного.

Алгоритм 1 - прямое решение. Мы перебираем все возможные суммы элементов, пока не найдем максимальную.
int maxSum1(vector<int> a)
{
1     int maxSum=0;
2     int N = a.size();
3     for (int i=0; i<N; ++i) {
4         for (int j=i; j<N; ++j) {
5             int sum = 0;
6             for (int k=i; k<=j; ++k)
7                 sum += a[k];
8             if (sum > maxSum)
9                 maxSum = sum;
10        }
11    }
12    return maxSum;
}

Грубый анализ: строки 1, 2 и 3 отбрасываем как несущественные. Внешний цикл (строка 3) выполняется
N раз. Средний цикл выполняется N-i раз, но, предполагая худшее, считаем, что он также выполняется N раз.
Внутренний цикл выполняется j-i+1 раз, но, опять предполагая худший сценарий, он может
выполниться все N раз. Таким образом, сложность всех циклов равна O(N*N*N) = O(N³).
Сложность строки 7 константна, то есть не влияет на сложность внутреннего цикла.
Сложность строк 8-9 во внутреннем цикле равна O(N²), так как они расположены внутри двойного цикла.
Таким образом, получаем, что максимальная сложность всей функции не выше N³, то есть maxSum1 = O(N³).

Точный анализ:
Время выполнения строки 7 равно 1,  время выполнения внутреннего цикла равно Σ(k=i..j)(1) = j-i+1.
Время выполнения среднего цикла равно Σ(j=i..N-1)(j-i+1) = (N-i+1)(N-i)/2.
Наконец, время выполнения внешнего цикла равно
Σ(i=0..N-1)( (N-i+1)(N-i)/2 ) = Σ(i=1..N)( (N-i+1)(N-i+2)/2 )
    = ½Σ(i=1..N)(i²) - (N+3/2)Σ(i=1..N)(i) + ½(N²+3N+2)Σ(i=1..N)(1)
    = ½(N(N+1)(2N+1)/6) - (N+3/2)(N(N+1)/2) + N(N²+3N+2)/2
    = (N³+3N²+2N)/6.

Так как это точное значение времени выполнения функции, то мы можем утверждать, что
maxSum1 = Θ(N³), более того, точная оценка дает в 6 раз лучшее время, чем грубая оценка.

Алгоритм 2 - оптимизация. Заметим, что в вышеприведенном алгоритме есть лишние вычисления:
так как Σ(k=i..j)(Ak) = Aj + Σ(k=i..j-1)(Ak), то строки 6-7 явно можно убрать.
int maxSum2(vector<int> a)
{
    int maxSum=0;
    int N=a.size();
    for (int i=0; i<N; ++i) {
        int sum=0;
        for (int j=i; j<N; ++j) {
            sum += a[j];
            if (sum > maxSum)
                maxSum = sum;
        }
    }
    return maxSum;
}
Этот алгоритм, очевидно, имеет сложность O(N²) (покажите это самостоятельно).

Алгоритм 3 - рекурсивный.
Этот алгоритм использует традиционный для рекурсивных алгоритмов прием "разделяй и властвуй".
Разобьем задачу на две примерно равные по размеру подзадачи, рекурсивно решим каждую,
а затем соединим вместе полученные решения.
Подпоследовательность с максимальной суммой может встретиться в одном из трех мест: либо целиком в левой
половине вектора, либо целиком в правой половине, либо и в левой и в правой. Первые два случая
можно решить рекурсивно. Третий случай можно решить, если взять максимальную сумму из первой половины,
включающую последний ее элемент, и максимальную сумму из второй половины, включающую первый
элемент второй половины, а затем сложить их. В качестве примера, рассмотрим вектор:

первая половина   вторая половина
4   -3   5   -2   -1   2   6   -2

Максимальная последовательность из первой половины - (а1..а3) (сумма равна 6),
из второй половины - (а6..а7) (сумма равна 8).
Максимальная сумма из первой половины, включающая ее последний элемент, равна 4 (а1..а4),
максимальная сумма из второй половины, включающая ее первый элемент, равна 7 (а5..а7).
Их сумма равна 4+7=11. Это больше, чем любая максимальная сумма из отдельных половин.
Таким образом, максимальная подпоследовательность равна (а1..а7) с суммой 11.

//Рекурсивная функция, вызываемая в реально используемой функции
int maxSumRec(vector<int> &a, int left, int right)
{
1     if (left==right) {//граничное условие - если элемент положительный, то берем его за максимальную сумму.
2         if (a[left]>0)
3             return a[left];
4         else
5             return 0;
6     }
7
8     int center = (left+right)/2;
9     int maxLeftSum = maxSumRec(a, left, center); //рекурсивные вызовы для левой
10    int maxRightSum = maxSumRec(a, center+1, right); //и правой половин
11
12    int maxLeftBorderSum = 0, leftBorderSum = 0;
13    for (int i=center; i>=left; --i) {
14        leftBurderSum += a[i];
15        if (leftBorderSum > maxLeftBorderSum)
16            maxLeftBorderSum = leftBorderSum;
17    }
18
19    int maxRightBorderSum = 0, rightBorderSum = 0;
20    for (int i=center+1; i<=right; ++i) {
21        rightBorderSum += a[i];
22        if (rightBorderSum > maxRightBorderSum)
23            maxRightBorderSum = rightBorderSum;
24    }
25    //сравнивает три числа и возвращает максимальное
26    return max3(maxLeftSum, maxRightSum, maxLeftBorderSum+maxRightBorderSum);
}
//Реально используемая функция
int maxSum3(vector<int> &a)
{
    return maxSumRec(a, 0, a.size()-1);
}

Оценить время выполнения рекурсивного алгоритма достаточно сложно. Пусть функция T(N) выражает алгоритм.
Пусть N=1, тогда выполнятся только строки 1-6, причем за константное время: T(1) = 1.
Иначе программа выполнит два рекурсивных вызова, два цикла for и некоторый дополнительный код.
Два цикла проходят по всем элементам подпоследовательности (от left до right), а тело циклов
выполняется за константное время, поэтому их сложность равна O(N).
Строки 1-8, 12, 19, 26 выполняются за константное время, поэтому ими можно пренебречь.
Остальная работа выплняется в строках 9-10, каждая из которых рекуррентно выполняет задачу
размером N/2, то есть их общее время работы равно 2T(N/2).
Таким образом, получаем:
  T(1)=1,
  T(N)=2T(N/2)+O(N)
Заменим O(N) на N, так как это не повлияет на общую оценку O(T(N)).
Получаем: T(1)=1, T(2)=2*1+2=4=2*2, T(4)=2*4+4=12=3*4, T(8)=2*12+8=32=8*4, T(16)=2*32+16=80=16*5.
Прослеживается следующая зависимость: если N = 2^k, то T(N) = N*(k+1) = N log₂N+N = O(N logN).
Если же N не является степенью двойки, то анализ немного усложняется, но можно показать,
что полученная оценка сложности не изменится.


Алгоритм 4 - самый сложный для понимания.
Покажем, что существует алгоритм поиска суммы максимальной подпоследовательности, имеющий
линейную сложность. Он основан на том факте, что отрицательное значение суммы явно не будет максимальным,
и элементы, дающие вклад в такую сумму, можно просто пропустить. Это позволяет нам полностью избавиться
от внешнего цикла, с небольшими изменениями внутреннего.
int maxSubSum4(vector<int> &a)
{
1    int maxSum=0, sum=0;
2    for (int j=0; j<a.size(); ++j) {
3        sum += a[j];
4        if (sum > maxSum)
5            maxSum = sum;
6        else if (sum < 0)
7            sum = 0;
8    }
9    return maxSum;
}
В этом алгоритме всего один цикл, итерирующий по всем элементам вектора, а тело цикла требует
константного времени выполнения. Таким образом, очевидно, что maxSubSum4 = O(N).
Доказать строго, что четвертый алгоритм корректен, довольно сложно.

Примеры логарифмических алгоритмов
----------------------------------

При оценке сложности алгоритмов можно использовать следующее правило:

Алгоритм имеет сложность O(log N), если разделение задачи на части (обычно на две равные)
требует постоянного времени (то есть O(1)).
Алгоритм имеет линейную сложность, если константное время требуется на уменьшение задачи
на единицу.
Следует также понимать, что если входные данные представляют собой список из N элементов,
то только на чтение этих элементов потребуется время N (что больше log N), поэтому оценивать алгоритмы
логарифмической сложности следует без учета затрат на чтение данных.

1. Бинарный поиск.
   ---------------

Пусть вектор a содержит отсортированные по возрастанию числа. Требуется найти индекс числа x.

Очевидное решение - воспользоваться линейным поиском, то есть перебрать все элементы, пока
не найдем искомый. Однако линейный поиск не учитывает тот факт, что вектор уже отсортирован.
Поступим иначе:
1. Сравним x со средним элементом. Если они равны, то мы нашли искомый элемент. Если нет, то:
2. Очевидно, что раз вектор отсортирован по возрастанию, то если x меньше среднего, то он расположен
слева от него (в левой половине вектора). Если же x больше среднего элемента, то ищем его в правой
половине вектора.
int binary_search(const vector<int> &a, int x)
{
    int low=0, high=a.size()-1;
    while(low<=high) {
        int mid=(low+high)/2;
        if (a[mid]<x)
            low=mid+1; //перемещаем левую границу на левую границу правой половины
        else if (a[mid]>x)
            high=mid-1; //перемещаем правую границу на правую границу левой половины
        else
            return mid; //x==mid - нашли элемент в позиции mid
    }
    return -1; //не нашли элемент
}

Очевидно, вся работа внутри цикла выполняется за константное время O(1). Оценим время,
требуемое на все итерации. Цикл начинается при high-low=N-1 и заканчивается при high-low>=-1.
Каждый раз размер интервала делится пополам (в худшем случае), то есть общее число итераций
в худшем случае равно log(N-1)+2. Таким образом, сложность алгоритма равна O(log N).

2. Алгоритм Евклида
   ----------------

Второй пример - вычисление наибольшего общего делителя двух целых чисел.
Пусть M >= N, тогда
long long gcd(long long m, long long n)
{
    while(n!=0) {
        long long rem = m%n;
        m=n;
        n=rem;
    }
    return m;
}

Алгоритм работает, постоянно вычисляя остатки, пока в остатке не получим 0. Последний
ненулевой остаток - и есть наибольший общий делитель. Если M=1989, N=1590, то последовательность
остатков будет 399, 393, 6, 3, 0. Т.о., gcd(1989, 1590)=3.
Сложность алгоритма зависит от длины последовательности остатков. Из примера видно, что
остаток может снижаться неравномерно. Докажем, что после итерации цикла остаток уменьшается
сильнее, чем в два раза, то есть если M>N, то M mod N < M/2.
Действительно, если N <= M/2, то так как остаток меньше N, то утверждение верно. Если же N>M/2,
то тогда N велючено в M только один раз, причем остаток равен M-N<M/2. Утверждение доказано.

Так как каждую итерацию остаток уменьшается более чем вдвое, то количество итераций алгоритма
не может превысить 2 log₂N = O(log N).
сложными вычислениями можно показать, что среднее время выполнения алгоритма Евклида равно
(12 ln(2) ln(N))/π²+1.47.

3. Возведение в степень
   --------------------

Пусть требуется возвести целое число X в целую степень N. Очевидное решение - перемножить N чисел X.
Это, очевидно, даст сложность O(N). Однако можно улучшить результат, если заметить, что
X^N = X^(N/2) * X^(N/2), если N четно. Если же N нечетно, то X^N = X^((N-1)/2)*X^((N-1)/2)*X.
Например, для прямого вычисления X^62 понадобится 62 умножения.
Если же воспользоваться замечанием выше, то потребуется только 9 умножений:
X³=(X²)X, X⁷=(X³)²X, X¹⁵=(X⁷)²X, X³¹=(X¹⁵)²X, X⁶²=(X³¹)²
Так как для уменьшения задачи вдвое требуется только два умножения (при N нечетном), и одно
умножение (при N четном), то количество умножений не превышает 2logN.
long long pow(long long x, int n)
{
    if (n==0) return 1;
    if (n==1) return x;
    if (isEven(n))
        return pow(x*x, n/2);
    else
        return pow(x*x,n/2)*x;
}
Таким образом, этот алгоритм имеет сложность O(log N) (если отбросить коэффициенты).

Задания:
--------
1. Упорядочить по скорости роста: N, √N, N^1.5, N², NlogN, Nlog(logN), Nlog²N, Nlog(N²),
   2/N, 2^N, 2^(N/2), 37, N²logN, N³.
2. Пусть T₁(N) = O(f(N)), T₂(N) = O(f(N)). Что из нижеперечисленного верно?
   T₁(N)+T₂(N) = O(f(N))
   T₁(N)-T₂(N) = o(f(N))
   T₁(N)/T₂(N) = O(1)
   T₁(N) = O(T₂(N))
3. Какая функция растет быстрее: NlogN или N^(1+ε/√(logN)), ε>0
4. Докажите, что для любой константы k справедливо (logN)^k = o(N).
5. Судья постановил городу выплату штрафа. В первый день город выплатит 2$, в каждый
   следующий день сумма штрафа возводится в квадрат: 4, 16, 256, 65536...
   а) Каков будет штраф в день N?
   б) Сколько дней потребуется, чтобы штраф превысил D$? (дайте оценку O(D)).
6. Для каждого из следующих шести фрагментов кода дайте оценку O(N)
   а)
   sum=0;
   for (i=0; i<n; ++i) ++sum;
   б)
   sum=0;
   for (i=0; i<n; ++i)
       for (j=0; j<n; ++j)
           ++sum;
   в)
   sum=0;
   for (i=0; i<n; ++i)
       for (j=0; j<n*n; ++j)
           ++sum;
   г)
   sum=0;
   for (i=0; i<n; ++i)
       for (j=0; j<i; ++j)
           ++sum;
   д)
   sum=0;
   for (i=0; i<n; ++i)
       for (j=0; j<i*i; ++j)
           for (k=0; k<j; ++k)
               ++sum;
   е)
   sum=0;
   for (i=1; i<n; ++i)
       for (j=1; j<i*i; ++j)
           if (j%i==0)
               for (k=0; k<j; ++k)
                   ++sum;

7. Для обычных приемов вычисления от руки определите сложность следующих операций:
   а) сложение двух N-значных чисел
   б) умножение двух N-значных чисел
   в) деление двух N-значных чисел
8. Алгоритм выполняется за 0,5 мс для размера данных 100. Сколько будет выполняться
   тот же алгоритм для размера 500, если алгоритм:
   а) линейный
   б) O(NlogN)
   в) квадратичный
   г) кубический
9. Алгоритм выполняется за 0,5 мс для размера данных 100. Какой объем данных этот же
   алгоритм сможет обработать за 1 мин, если алгоритм
   а) линейный
   б) O(NlogN)
   в) квадратичный
   г) кубический
10. Сколько времени потребуется для вычисления полинома Σ(i=0..N)ai*x^i
    а) используя обычный алгоритм возведения в степень
    б) используя оптимизированный алгоритм возведения в степень, приведенный выше.
11. Рассмотрим алгоритм Хорнера вычисления полинома Σ(i=0..N)ai*x^i
   poly = 0;
   for (i=n; i>=0; --i)
       poly = x * poly + a[i];
   Напишите функцию, реализующую этот алгоритм.
   Распишите все этапы вычисления значения функции f(x) = 4x⁴+8x³+x+2 для x=3.
   Объясните, почему этот алгоритм работает.
   Оцените сложность алгоритма.
12. Важная задача в числовом анализе - это поиск решения уравнения f(x)=0.
    Если функция непрерывна, и если есть две такие точки a и b, что f(a) и f(b) имеют
    разные знаки, то на интервале (a, b) есть как минимум один корень функции f(x).
    Напишите алгоритм бинарного поиска корня функции для заданных f, a, b.
    Как будет записываться условие прекращения расчета?
    Совет: передать функцию в функцию можно по указателю: если функция f принимает
    один вещественный аргумент и возвращает одно вещественное число (то есть y=f(x)),
    то указатель на функцию будет иметь тип  double (*)(double)
    Определите новый тип: using fun = double (*)(double);
    И передавайте аргумент этого типа:
    double computeRoot(fun f, double a, double b);
13. Напишите эффективный алгоритм, определяющий, содержится ли в отсортированном векторе
    целых чисел такое число i, что A[i]=i. Оцените его сложность.
14. Решето Эратосфена - эффективный алгоритм поиска всех простых чисел, меньших N:
    - Составим таблицу чисел от 2 до N.
    а) Возьмем наименьшее невычеркнутое число i - оно будет простым.
    б) Вычеркнем каждое i-е число в таблице: 2i, 3i, 4i... - они не являются простыми.
    в) перейдем к шагу а).
    Алгоритм заканчивается, когда i > √N.
    Оцените сложность алгоритма Эратосфера.
15. Покажите, что X⁶² можно вычислить всего за 8 умножений.
16. Программы A и B имеют время выполнения, не превышающее 150Nlog₂N и N² соответственно в
    наихудшем случае. Ответьте на следующие вопросы:
    а) Какая программа работает быстрее при больших значениях N (N>10000)?
    б) Какая программа работает быстрее при малых значениях N (N<100)?
    в) Какая программа работает быстрее при средних значениях N (N=1000)?
    г) Возможно ли, что программа B будет работать быстрее программы A при любых входных данных?
17. Входные данные - матрица NxN чисел, в которой в каждом ряду числа возрастают слева направо,
    и в каждом столбце числа возрастают сверху вниз. Напишите алгоритм сложности O(N),
    определяющий, содержится ли число X в матрице.

*/

#endif // ALGO_COMPLEXITY_H
